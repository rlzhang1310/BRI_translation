{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import zipfile\n",
    "import json\n",
    "import io\n",
    "import spacy\n",
    "import csv\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## s3 host to access data from UMIACS\n",
    "s3_host = 'https://obj.umiacs.umd.edu'\n",
    "access_key_id = \"xxxxx\"\n",
    "secret_access_key = \"xxxxx\"\n",
    "\n",
    "s3 = boto3.client('s3', \n",
    "                  endpoint_url=s3_host, \n",
    "                  aws_access_key_id=access_key_id, \n",
    "                  aws_secret_access_key=secret_access_key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## processes tmrc dataset\n",
    "def process_tmrc(folder_prefix):\n",
    "    ## we will collect the data with a list then create df at the end (most efficient with runtime)\n",
    "    char_count = 0\n",
    "    word_count = 0\n",
    "    sentence_count = 0\n",
    "    response = s3.list_objects_v2(Bucket=\"twitter.tmrc\", Prefix=folder_prefix)\n",
    "    files = []\n",
    "    ## collect all the filenames to be processed \n",
    "    for obj in response.get('Contents', []):\n",
    "        object_key = obj['Key']\n",
    "        if object_key.endswith('.zip'):\n",
    "            files.append(object_key)\n",
    "    ##  process each file\n",
    "    for file in files:\n",
    "        zip_object = s3.get_object(Bucket=\"twitter.tmrc\", Key=file)\n",
    "        zip_contents = zip_object['Body'].read()\n",
    "        zip_file = zipfile.ZipFile(io.BytesIO(zip_contents), 'r')\n",
    "        for file_info in zip_file.infolist():\n",
    "            with zip_file.open(file_info) as json_file:\n",
    "                file_name = file_info.filename                    \n",
    "                ## we are only interested in the tweet file\n",
    "                if not file_name.endswith(\"-tweet.json\"):\n",
    "                    continue\n",
    "                try:\n",
    "                    json_data = json_file.read().decode('utf-8')\n",
    "                except: \n",
    "                    print(\"this is a text file\")\n",
    "                parsed_data = json.loads(json_data)\n",
    "                for ind_data in parsed_data:\n",
    "                    tweet = ind_data[\"tweet\"][\"tweet_text\"]\n",
    "                    # print(tweet)\n",
    "                    char_count += len(tweet)\n",
    "                    word_count += len(tweet.split(\" \"))\n",
    "                    sentence_count += 1\n",
    "    return (char_count, word_count, sentence_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## counting helper to use apply\n",
    "def helper(tweet, counts):\n",
    "    raw_text = tweet[\"tweet_text\"]\n",
    "    if type(raw_text) != str:   ## one entry that has \"nan\" as the tweet text\n",
    "        raw_text = str(raw_text)\n",
    "    counts['char_count'] += len(raw_text)\n",
    "    counts['word_count'] += len(raw_text.split(\" \"))\n",
    "    counts[\"sentence_count\"] += 1\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getdf_twitterei(file):\n",
    "    zip_object = s3.get_object(Bucket='twitter.ei', Key=file)\n",
    "    zip_contents = zip_object['Body'].read()\n",
    "    zip_file = zipfile.ZipFile(io.BytesIO(zip_contents), 'r')\n",
    "    for file_info in zip_file.infolist():\n",
    "        with zip_file.open(file_info) as csv_file:\n",
    "            df = None\n",
    "            try:\n",
    "                if df == None:\n",
    "                    df = pd.read_csv(csv_file)\n",
    "                else:\n",
    "                    df = pd.concat([df, pd.read_csv(csv_file)], axis=0)\n",
    "            except:\n",
    "                print(f\"{csv_file.filename} is not a csv file\")\n",
    "    df[\"tweet_id\"] = df[\"tweetid\"]\n",
    "    return df[[\"tweet_id\", \"tweet_language\", \"tweet_text\"]]\n",
    "\n",
    "def process_twitterei(df):\n",
    "    counts = {'char_count': 0, 'word_count': 0, 'sentence_count': 0}\n",
    "    df.apply(lambda row: helper(row, counts), axis=1)\n",
    "    return (counts['char_count'], counts['word_count'], counts['sentence_count'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmrc_folder_prefix_lst = ['August_2022/TMRC14_APAC_1/', \n",
    "                          'August_2022/TMRC14_APAC_2/', \n",
    "                          'October_2022/TMRC15_APAC_3/']\n",
    "twitterei_folder_prefix_lst = [\"2019_08/china_082019_1/china_082019_1_tweets_csv_unhashed.zip\",\n",
    "                               \"2019_08/china_082019_2/china_082019_2_tweets_csv_unhashed.zip\",\n",
    "                               \"2019_08/china_082019_3/china_082019_3_tweets_csv_unhashed.zip\",\n",
    "                               \"2020_05/china_052020/china_052020_tweets_csv_unhashed.zip\", \n",
    "                               \"2020_09/thailand_092020/thailand_092020_tweets_csv_unhashed.zip\"]\n",
    "\n",
    "## this dict will be in the format of campaign_name, data\n",
    "campaign_data_dict = dict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TMRC14_APAC_1\n",
      "(8844962, 1206149, 66251)\n",
      "TMRC14_APAC_2\n",
      "(34977662, 4429453, 274207)\n",
      "TMRC15_APAC_3\n",
      "(15545966, 2021695, 131046)\n"
     ]
    }
   ],
   "source": [
    "for f in tmrc_folder_prefix_lst:\n",
    "    name = f.split('/')[1]\n",
    "    print(name)\n",
    "    campaign_data_dict[name] = process_tmrc(f)\n",
    "    print(campaign_data_dict[name])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "china_082019_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/r4/sgr1zrxx0038xwsxj6n3k8900000gn/T/ipykernel_69157/1831553457.py:10: DtypeWarning: Columns (6,30) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(csv_file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(162553854, 22376563, 1898108)\n",
      "china_082019_2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/r4/sgr1zrxx0038xwsxj6n3k8900000gn/T/ipykernel_69157/1831553457.py:10: DtypeWarning: Columns (30) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(csv_file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(151516180, 22048287, 1701257)\n",
      "china_082019_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/r4/sgr1zrxx0038xwsxj6n3k8900000gn/T/ipykernel_69157/1831553457.py:10: DtypeWarning: Columns (30) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(csv_file)\n",
      "/var/folders/r4/sgr1zrxx0038xwsxj6n3k8900000gn/T/ipykernel_69157/1831553457.py:10: DtypeWarning: Columns (30) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(csv_file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(198223929, 22934200, 2875334)\n",
      "china_052020\n",
      "(33048639, 1861761, 348608)\n",
      "thailand_092020\n",
      "(1937278, 126841, 21385)\n"
     ]
    }
   ],
   "source": [
    "for f in twitterei_folder_prefix_lst:\n",
    "    name = f.split('/')[1]\n",
    "    print(name)\n",
    "    df = getdf_twitterei(f)\n",
    "    campaign_data_dict[name] = process_twitterei(df)\n",
    "    print(campaign_data_dict[name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TMRC14_APAC_1\n",
      "(8844962, 1206149, 66251)\n",
      "TMRC14_APAC_2\n",
      "(34977662, 4429453, 274207)\n",
      "TMRC15_APAC_3\n",
      "(15545966, 2021695, 131046)\n",
      "china_082019_1\n",
      "(162553854, 22376563, 1898108)\n",
      "china_082019_2\n",
      "(151516180, 22048287, 1701257)\n",
      "china_082019_3\n",
      "(198223929, 22934200, 2875334)\n",
      "china_052020\n",
      "(33048639, 1861761, 348608)\n",
      "thailand_092020\n",
      "(1937278, 126841, 21385)\n"
     ]
    }
   ],
   "source": [
    "for k,v in campaign_data_dict.items():\n",
    "    print(k)\n",
    "    print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TMRC\n",
      "59368590, 7657297, 471504\n",
      "TwitterEI\n",
      "547279880, 69347652, 6844692\n",
      "ALL\n",
      "606648470, 77004949, 7316196\n"
     ]
    }
   ],
   "source": [
    "tmrc_c = 0\n",
    "tmrc_w = 0\n",
    "tmrc_s = 0\n",
    "twitterei_c = 0\n",
    "twitterei_w = 0\n",
    "twitterei_s = 0\n",
    "for k,v in campaign_data_dict.items():\n",
    "    if k.startswith(\"TMRC\"):\n",
    "        tmrc_c += v[0]\n",
    "        tmrc_w += v[1]\n",
    "        tmrc_s += v[2]\n",
    "    else:\n",
    "        twitterei_c += v[0]\n",
    "        twitterei_w += v[1]\n",
    "        twitterei_s += v[2]\n",
    "\n",
    "print(\"TMRC\")\n",
    "print(f\"{tmrc_c}, {tmrc_w}, {tmrc_s}\")\n",
    "print(\"TwitterEI\")\n",
    "print(f\"{twitterei_c}, {twitterei_w}, {twitterei_s}\")\n",
    "print(\"ALL\")\n",
    "print(f\"{tmrc_c + twitterei_c}, {tmrc_w + twitterei_w}, {tmrc_s + twitterei_s}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
