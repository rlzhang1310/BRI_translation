{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import time\n",
    "\n",
    "## translation libraries\n",
    "import translators as ts\n",
    "from googletrans import Translator as gt\n",
    "from deep_translator import GoogleTranslator\n",
    "from translate import Translator as tlr\n",
    "\n",
    "## sentiment analysis libraries\n",
    "import spacy\n",
    "from spacytextblob.spacytextblob import SpacyTextBlob\n",
    "import nltk\n",
    "\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "# nltk.download('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['en', 'in', 'ur', 'zh', 'und', 'ar', 'pt']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "language_files = [\n",
    "    \"TMRC14_APAC_1\", \"TMRC14_APAC_2\", \"TMRC14_APAC_3\", \n",
    "    \"twitterrei_china_052020\", \"twitterrei_china_082019_1\",\n",
    "    \"twitterrei_china_082019_2\", \"twitterrei_china_082019_3\", \n",
    "    \"twitterrei_thailand_092020\"\n",
    "]\n",
    "root = '/Users/rlzhang1310/Coding/buntain/language_data/'\n",
    "end = '.csv'\n",
    "\n",
    "top_languages = pd.DataFrame()\n",
    "\n",
    "for file in language_files:\n",
    "    src = root + file + end\n",
    "    df = pd.read_csv(src)\n",
    "    if \"tweet_language\" in df.columns:\n",
    "        df[\"language\"] = df[\"tweet_language\"]\n",
    "        df.drop([\"tweet_language\"], axis=1, inplace=True)\n",
    "    top_languages = pd.concat([top_languages, df], axis=0)\n",
    "\n",
    "top_languages = top_languages.groupby('language').sum().reset_index()\n",
    "top_languages = top_languages.sort_values(by='count', ascending=False)\n",
    "total_count = top_languages[\"count\"].sum()\n",
    "\n",
    "top_languages_lst = top_languages.head(7)['language'].tolist()\n",
    "top_languages_lst\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.914366900848165\n"
     ]
    }
   ],
   "source": [
    "count = top_languages[top_languages['language'].isin(top_languages_lst)][\"count\"].sum()\n",
    "print(count / total_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rlzhang1310/Library/Python/3.9/lib/python/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "## spacy sentiment analysis\n",
    "en_nlp = spacy.load('en_core_web_sm')\n",
    "en_nlp.add_pipe('spacytextblob')\n",
    "\n",
    "def get_spacy_sentiment(text, en_nlp):\n",
    "    doc = en_nlp(text)\n",
    "    return doc._.blob.polarity   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ts_tester(text, to):\n",
    "    retries = 5\n",
    "    delay=1\n",
    "    for attempt in range(retries):\n",
    "        try:\n",
    "            to_in = ts.translate_text(text, from_language='en', to_language=to)\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"Error during translation to {to}: {e}. Retrying... ({attempt + 1}/{retries})\")\n",
    "            time.sleep(delay)\n",
    "    else:\n",
    "        print(f\"Failed to translate text '{text}' to {to} after {retries} attempts.\")\n",
    "        return None\n",
    "\n",
    "    # Try translating back to English\n",
    "    for attempt in range(retries):\n",
    "        try:\n",
    "            back_en = ts.translate_text(to_in, from_language=to, to_language='en')\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"Error during back translation to English: {e}. Retrying... ({attempt + 1}/{retries})\")\n",
    "            time.sleep(delay)\n",
    "    else:\n",
    "        print(f\"Failed to back translate text '{to_in}' to English after {retries} attempts.\")\n",
    "        return None\n",
    "\n",
    "    return get_spacy_sentiment(back_en, en_nlp)\n",
    "    # to_in = ts.translate_text(text, from_language='en',to_language=to)\n",
    "    # back_en = ts.translate_text(to_in,from_language=to, to_language='en')\n",
    "    # return get_spacy_sentiment(back_en, en_nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def googletrans_tester(text, to):\n",
    "    googletrans_translator = gt()\n",
    "        # Try translating from English to the target language\n",
    "    retries =5\n",
    "    delay= 10\n",
    "    for attempt in range(retries):\n",
    "        try:\n",
    "            to_in_trans = googletrans_translator.translate(text, src='en', dest=to)\n",
    "            to_in = to_in_trans.text\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"Error during translation to {to}: {e}. Retrying... ({attempt + 1}/{retries})\")\n",
    "            time.sleep(delay)\n",
    "    else:\n",
    "        print(f\"Failed to translate text '{text}' to {to} after {retries} attempts.\")\n",
    "        return None\n",
    "\n",
    "    # Try translating back to English\n",
    "    for attempt in range(retries):\n",
    "        try:\n",
    "            back_en = googletrans_translator.translate(to_in, src=to, dest='en')\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"Error during back translation to English: {e}. Retrying... ({attempt + 1}/{retries})\")\n",
    "            time.sleep(delay)\n",
    "    else:\n",
    "        print(f\"Failed to back translate text '{to_in}' to English after {retries} attempts.\")\n",
    "        return None\n",
    "\n",
    "    return get_spacy_sentiment(back_en.text, en_nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deep_tester(text, to):\n",
    "    to_in = GoogleTranslator(source='en', target=to).translate(text)\n",
    "    back_en = GoogleTranslator(source=to, target='en').translate(to_in)\n",
    "    return get_spacy_sentiment(back_en, en_nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "email = \"rlzhang49@gmail.com\"\n",
    "def translate_tester(text, to):\n",
    "    print(text)\n",
    "    to_in = tlr(from_lang='en', to_lang=to, email=email).translate(text)\n",
    "    print(to_in)\n",
    "    back_en = tlr(from_lang=to,to_lang=\"en\", email=email).translate(to_in)\n",
    "    print(back_en)\n",
    "    return get_spacy_sentiment(back_en, en_nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## https://www.kaggle.com/datasets/saurabhshahane/twitter-sentiment-dataset\n",
    "twitter_data = pd.read_csv(\"/Users/rlzhang1310/Coding/buntain/twitter_dataset/Twitter_Data.csv\")\n",
    "twitter_data[\"text\"] = twitter_data[\"clean_text\"]\n",
    "twitter_data[\"score\"] = twitter_data[\"category\"]\n",
    "twitter_data = twitter_data.drop([\"clean_text\", \"category\"], axis=1)\n",
    "twitter_data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>score</th>\n",
       "      <th>spacy_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>76734</th>\n",
       "      <td>â‚¹72000 election promise modi promised lakh dur...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105563</th>\n",
       "      <td>what does amazing interview modi with arnab go...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46243</th>\n",
       "      <td>congratulations the government why dont like t...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147520</th>\n",
       "      <td>hit like you think modi will our next also</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79709</th>\n",
       "      <td>this needs reach many people possible narendra...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83397</th>\n",
       "      <td>bhakts can say tomorrow ask them who give birt...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121606</th>\n",
       "      <td>ensureed this north korea than what happens wi...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154144</th>\n",
       "      <td>deepender losing because these factors jat rio...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159522</th>\n",
       "      <td>are very afraid modi ghe man his words bolta h...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144468</th>\n",
       "      <td>jai sia ram watch thulasi nambiar our own sani...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.725</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  score  \\\n",
       "76734   â‚¹72000 election promise modi promised lakh dur...    0.0   \n",
       "105563  what does amazing interview modi with arnab go...    1.0   \n",
       "46243   congratulations the government why dont like t...    0.0   \n",
       "147520        hit like you think modi will our next also     0.0   \n",
       "79709   this needs reach many people possible narendra...    1.0   \n",
       "...                                                   ...    ...   \n",
       "83397   bhakts can say tomorrow ask them who give birt...    0.0   \n",
       "121606  ensureed this north korea than what happens wi...   -1.0   \n",
       "154144  deepender losing because these factors jat rio...    0.0   \n",
       "159522  are very afraid modi ghe man his words bolta h...   -1.0   \n",
       "144468  jai sia ram watch thulasi nambiar our own sani...    1.0   \n",
       "\n",
       "        spacy_sentiment  \n",
       "76734             0.000  \n",
       "105563            0.600  \n",
       "46243             0.000  \n",
       "147520            0.000  \n",
       "79709             0.250  \n",
       "...                 ...  \n",
       "83397             0.000  \n",
       "121606           -0.800  \n",
       "154144            0.000  \n",
       "159522           -0.780  \n",
       "144468            0.725  \n",
       "\n",
       "[1000 rows x 3 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_data = twitter_data.sample(n=1000)\n",
    "twitter_data[\"spacy_sentiment\"] = twitter_data[\"text\"].apply(get_spacy_sentiment, en_nlp=en_nlp)\n",
    "twitter_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/r4/sgr1zrxx0038xwsxj6n3k8900000gn/T/ipykernel_20166/1266798558.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  head[\"testing\"] = head.apply(lambda row: googletrans_tester(row['text'], to='id'), axis=1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>score</th>\n",
       "      <th>spacy_sentiment</th>\n",
       "      <th>id_ts</th>\n",
       "      <th>id_gs</th>\n",
       "      <th>id_dp</th>\n",
       "      <th>id_tr</th>\n",
       "      <th>ur_ts</th>\n",
       "      <th>testing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>76734</th>\n",
       "      <td>â‚¹72000 election promise modi promised lakh dur...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105563</th>\n",
       "      <td>what does amazing interview modi with arnab go...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46243</th>\n",
       "      <td>congratulations the government why dont like t...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.30</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147520</th>\n",
       "      <td>hit like you think modi will our next also</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79709</th>\n",
       "      <td>this needs reach many people possible narendra...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  score  \\\n",
       "76734   â‚¹72000 election promise modi promised lakh dur...    0.0   \n",
       "105563  what does amazing interview modi with arnab go...    1.0   \n",
       "46243   congratulations the government why dont like t...    0.0   \n",
       "147520        hit like you think modi will our next also     0.0   \n",
       "79709   this needs reach many people possible narendra...    1.0   \n",
       "\n",
       "        spacy_sentiment  id_ts  id_gs  id_dp  id_tr  ur_ts  testing  \n",
       "76734              0.00   0.00    0.0    0.0    0.0   0.00      0.0  \n",
       "105563             0.60   0.75    0.6    0.6    0.6   0.60      0.6  \n",
       "46243              0.00   0.00    0.0    0.0    0.0  -0.30      0.0  \n",
       "147520             0.00   0.00    0.0    0.0    0.0   0.00      0.0  \n",
       "79709              0.25   0.25    0.5    0.5    0.5   0.25      0.5  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "head = twitter_data.head(5)\n",
    "head[\"testing\"] = head.apply(lambda row: googletrans_tester(row['text'], to='id'), axis=1)\n",
    "head\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc_dict():\n",
    "    d = dict()\n",
    "    d[\"rmse\"] = 0\n",
    "    d[\"mae\"] = 0\n",
    "    d[\"pos_correct\"] = 0\n",
    "    d[\"neg_correct\"] = 0\n",
    "    d[\"neu_correct\"] = 0\n",
    "    d[\"pos_total\"] = 0\n",
    "    d[\"neg_total\"] = 0\n",
    "    d[\"neu_total\"] = 0\n",
    "    return d\n",
    "id_ts = acc_dict()\n",
    "id_gs = acc_dict()\n",
    "id_dp = acc_dict()\n",
    "id_tr = acc_dict()\n",
    "\n",
    "ur_ts = acc_dict()\n",
    "ur_gs = acc_dict()\n",
    "ur_dp = acc_dict()\n",
    "ur_tr = acc_dict()\n",
    "\n",
    "zh_ts = acc_dict()\n",
    "zh_gs = acc_dict()\n",
    "zh_dp = acc_dict()\n",
    "zh_tr = acc_dict()\n",
    "\n",
    "ar_ts = acc_dict()\n",
    "ar_gs = acc_dict()\n",
    "ar_dp = acc_dict()\n",
    "ar_tr = acc_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculation_helper(actual, output, acc):\n",
    "    diff = abs(output - actual)\n",
    "    acc[\"rmse\"] += diff**2\n",
    "    acc[\"mae\"] += diff\n",
    "    if actual == 0:\n",
    "        acc[\"neu_total\"] += 1\n",
    "        if output == 0:\n",
    "            acc[\"neu_correct\"] += 1\n",
    "    elif actual > 0:\n",
    "        acc[\"pos_total\"] += 1\n",
    "        if output > 0:\n",
    "            acc[\"pos_correct\"] += 1\n",
    "    else:\n",
    "        acc[\"neg_total\"] += 1\n",
    "        if output < 0:\n",
    "            acc[\"neg_correct\"] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_data[\"id_ts\"] = twitter_data.apply(lambda row: ts_tester(row['text'], to='id'), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_data[\"id_gs\"] = twitter_data.apply(lambda row: googletrans_tester(row[\"text\"], to='id'), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_data[\"id_dp\"] = twitter_data.apply(lambda row: deep_tester(row[\"text\"], to='id'), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_data[\"id_tr\"] = twitter_data.apply(lambda row: translate_tester(row[\"text\"], to='id'), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indonesian Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76734     None\n",
       "105563    None\n",
       "46243     None\n",
       "147520    None\n",
       "79709     None\n",
       "          ... \n",
       "83397     None\n",
       "121606    None\n",
       "154144    None\n",
       "159522    None\n",
       "144468    None\n",
       "Length: 1000, dtype: object"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_data.apply(lambda row: calculation_helper(row[\"spacy_sentiment\"], row[\"id_ts\"], id_ts), axis=1)\n",
    "twitter_data.apply(lambda row: calculation_helper(row[\"spacy_sentiment\"], row[\"id_gs\"], id_gs), axis=1)\n",
    "twitter_data.apply(lambda row: calculation_helper(row[\"spacy_sentiment\"], row[\"id_dp\"], id_dp), axis=1)\n",
    "twitter_data.apply(lambda row: calculation_helper(row[\"spacy_sentiment\"], row[\"id_tr\"], id_tr), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68\n",
      "\n",
      "ts results\n",
      "rmse: 1.7414958528881879, mae: 6.792227032227032\n",
      "positive accuracy: 0.9706, negative accuracy: 0.75, neutral accuracy: 0.8182, total accuracy: 0.8824\n",
      "\n",
      "gs results\n",
      "rmse: 0.9057156647430747, mae: 4.330768398268397\n",
      "positive accuracy: 0.9706, negative accuracy: 0.75, neutral accuracy: 0.8636, total accuracy: 0.8971\n",
      "\n",
      "dp results\n",
      "rmse: 1.8452191484652671, mae: 6.826931216931217\n",
      "positive accuracy: 0.8824, negative accuracy: 0.75, neutral accuracy: 0.8636, total accuracy: 0.8529\n",
      "\n",
      "tr results\n",
      "rmse: 1.1275553790427277, mae: 4.128578643578644\n",
      "positive accuracy: 0.8824, negative accuracy: 0.9167, neutral accuracy: 1.0, total accuracy: 0.9265\n"
     ]
    }
   ],
   "source": [
    "dropped_invalid_tr = twitter_data[twitter_data[\"id_tr\"] != 0.34]\n",
    "print(len(dropped_invalid_tr))\n",
    "id_test_ts = acc_dict()\n",
    "id_test_gs = acc_dict()\n",
    "id_test_dp = acc_dict()\n",
    "id_test_tr = acc_dict()\n",
    "dropped_invalid_tr.apply(lambda row: calculation_helper(row[\"spacy_sentiment\"], row[\"id_ts\"], id_test_ts), axis=1)\n",
    "dropped_invalid_tr.apply(lambda row: calculation_helper(row[\"spacy_sentiment\"], row[\"id_gs\"], id_test_gs), axis=1)\n",
    "dropped_invalid_tr.apply(lambda row: calculation_helper(row[\"spacy_sentiment\"], row[\"id_dp\"], id_test_dp), axis=1)\n",
    "dropped_invalid_tr.apply(lambda row: calculation_helper(row[\"spacy_sentiment\"], row[\"id_tr\"], id_test_tr), axis=1)\n",
    "\n",
    "def print_res(d):\n",
    "    print(f'rmse: {math.sqrt(d[\"rmse\"])}, mae: {d[\"mae\"]}')\n",
    "    print(f'positive accuracy: {round(d[\"pos_correct\"] / d[\"pos_total\"], 4)}, '\n",
    "          f'negative accuracy: {round(d[\"neg_correct\"] / d[\"neg_total\"], 4)}, '\n",
    "          f'neutral accuracy: {round(d[\"neu_correct\"] / d[\"neu_total\"], 4)}, '\n",
    "          f'total accuracy: {round((d[\"pos_correct\"] + d[\"neg_correct\"] + d[\"neu_correct\"]) / (d[\"pos_total\"] + d[\"neg_total\"] + d[\"neu_total\"]), 4)}')\n",
    "    \n",
    "print(\"\\nts results\")\n",
    "print_res(id_test_ts)\n",
    "print(\"\\ngs results\")\n",
    "print_res(id_test_gs)\n",
    "print(\"\\ndp results\")\n",
    "print_res(id_test_dp)\n",
    "print(\"\\ntr results\")\n",
    "print_res(id_test_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ts results\n",
      "rmse: 5.210072332618934, mae: 79.32066892906478\n",
      "positive accuracy: 0.8764, negative accuracy: 0.8, neutral accuracy: 0.8484, total accuracy: 0.849\n",
      "\n",
      "gs results\n",
      "rmse: 5.906385483899573, mae: 100.24026441860987\n",
      "positive accuracy: 0.818, negative accuracy: 0.698, neutral accuracy: 0.829, total accuracy: 0.792\n",
      "\n",
      "dp results\n",
      "rmse: 5.624881635834863, mae: 90.8202041992399\n",
      "positive accuracy: 0.8674, negative accuracy: 0.8082, neutral accuracy: 0.7742, total accuracy: 0.824\n",
      "\n",
      "tr results\n",
      "rmse: 11.803534465010184, mae: 310.17673451548313\n",
      "positive accuracy: 0.991, negative accuracy: 0.0449, neutral accuracy: 0.071, total accuracy: 0.474\n"
     ]
    }
   ],
   "source": [
    "# def print_res(d):\n",
    "#     print(f'rmse: {math.sqrt(d[\"rmse\"])},  mae: {d[\"mae\"]}')\n",
    "#     print(f'positive accuracy: {round(d[\"pos_correct\"] / d[\"pos_total\"], 4)}, negative accuracy: {round(d[\"neg_correct\"] / d[\"neg_total\"], 4)}, \n",
    "#           neutral accuracy: {round(d[\"neu_correct\"] / d[\"neu_total\"], 4)}, \n",
    "#           total accuracy: {round(d[\"pos_correct\"] + d[\"neg_correct\"] + d[\"neu_correct\"] / d[\"pos_total\"] + d[\"neg_total\"] + d[\"neu_total\"])}')\n",
    "\n",
    "def print_res(d):\n",
    "    print(f'rmse: {math.sqrt(d[\"rmse\"])}, mae: {d[\"mae\"]}')\n",
    "    print(f'positive accuracy: {round(d[\"pos_correct\"] / d[\"pos_total\"], 4)}, '\n",
    "          f'negative accuracy: {round(d[\"neg_correct\"] / d[\"neg_total\"], 4)}, '\n",
    "          f'neutral accuracy: {round(d[\"neu_correct\"] / d[\"neu_total\"], 4)}, '\n",
    "          f'total accuracy: {round((d[\"pos_correct\"] + d[\"neg_correct\"] + d[\"neu_correct\"]) / (d[\"pos_total\"] + d[\"neg_total\"] + d[\"neu_total\"]), 4)}')\n",
    "    \n",
    "print(\"\\nts results\")\n",
    "print_res(id_ts)\n",
    "print(\"\\ngs results\")\n",
    "print_res(id_gs)\n",
    "print(\"\\ndp results\")\n",
    "print_res(id_dp)\n",
    "print(\"\\ntr results\")\n",
    "print_res(id_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_data[\"ur_ts\"] = twitter_data.apply(lambda row: ts_tester(row[\"text\"], to='ur'), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during translation to ur: the JSON object must be str, bytes or bytearray, not NoneType. Retrying... (1/5)\n",
      "Error during translation to ur: the JSON object must be str, bytes or bytearray, not NoneType. Retrying... (1/5)\n",
      "Error during back translation to English: the JSON object must be str, bytes or bytearray, not NoneType. Retrying... (1/5)\n"
     ]
    }
   ],
   "source": [
    "twitter_data[\"ur_gs\"] = twitter_data.apply(lambda row: googletrans_tester(row[\"text\"], to='ur'), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_data[\"ur_dp\"] = twitter_data.apply(lambda row: deep_tester(row[\"text\"], to='ur'), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# twitter_data[\"ur_tr\"] = twitter_data.apply(lambda row: translate_tester(row[\"text\"], to='ur'), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76734     None\n",
       "105563    None\n",
       "46243     None\n",
       "147520    None\n",
       "79709     None\n",
       "          ... \n",
       "83397     None\n",
       "121606    None\n",
       "154144    None\n",
       "159522    None\n",
       "144468    None\n",
       "Length: 1000, dtype: object"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_data.apply(lambda row: calculation_helper(row[\"spacy_sentiment\"], row[\"ur_ts\"], ur_ts), axis=1)\n",
    "twitter_data.apply(lambda row: calculation_helper(row[\"spacy_sentiment\"], row[\"ur_gs\"], ur_gs), axis=1)\n",
    "twitter_data.apply(lambda row: calculation_helper(row[\"spacy_sentiment\"], row[\"ur_dp\"], ur_dp), axis=1)\n",
    "# twitter_data.apply(lambda row: calculation_helper(row[\"spacy_sentiment\"], row[\"ur_tr\"], ur_tr), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ts results\n",
      "rmse: 6.18293813360281, mae: 106.68266653254145\n",
      "positive accuracy: 0.8067, negative accuracy: 0.6857, neutral accuracy: 0.8032, total accuracy: 0.776\n",
      "\n",
      "gs results\n",
      "rmse: 7.012306690781921, mae: 126.25301932789432\n",
      "positive accuracy: 0.7596, negative accuracy: 0.6245, neutral accuracy: 0.7774, total accuracy: 0.732\n",
      "\n",
      "dp results\n",
      "rmse: 5.820969520104741, mae: 97.29823829873833\n",
      "positive accuracy: 0.8449, negative accuracy: 0.8041, neutral accuracy: 0.7742, total accuracy: 0.813\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nts results\")\n",
    "print_res(ur_ts)\n",
    "print(\"\\ngs results\")\n",
    "print_res(ur_gs)\n",
    "print(\"\\ndp results\")\n",
    "print_res(ur_dp)\n",
    "# print(\"\\ntr results\")\n",
    "# print_res(ur_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during back translation to English: 0. Retrying... (1/5)\n",
      "Error during back translation to English: 0. Retrying... (1/5)\n",
      "Error during translation to zh: 0. Retrying... (1/5)\n",
      "Error during translation to zh: 0. Retrying... (1/5)\n",
      "Error during translation to zh: 0. Retrying... (1/5)\n",
      "Error during back translation to English: 0. Retrying... (1/5)\n",
      "Error during back translation to English: 0. Retrying... (1/5)\n",
      "Error during translation to zh: 0. Retrying... (1/5)\n",
      "Error during back translation to English: 0. Retrying... (1/5)\n",
      "Error during translation to zh: 0. Retrying... (1/5)\n",
      "Error during translation to zh: 0. Retrying... (1/5)\n",
      "Error during back translation to English: 0. Retrying... (1/5)\n",
      "Error during translation to zh: 0. Retrying... (1/5)\n",
      "Error during back translation to English: 0. Retrying... (1/5)\n",
      "Error during back translation to English: 0. Retrying... (1/5)\n",
      "Error during translation to zh: 0. Retrying... (1/5)\n",
      "Error during back translation to English: 0. Retrying... (1/5)\n",
      "Error during back translation to English: 0. Retrying... (2/5)\n"
     ]
    }
   ],
   "source": [
    "twitter_data[\"zh_ts\"] = twitter_data.apply(lambda row: ts_tester(row[\"text\"], to='zh'), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during back translation to English: the JSON object must be str, bytes or bytearray, not NoneType. Retrying... (1/5)\n",
      "Error during translation to zh-CN: the JSON object must be str, bytes or bytearray, not NoneType. Retrying... (1/5)\n",
      "Error during back translation to English: the JSON object must be str, bytes or bytearray, not NoneType. Retrying... (1/5)\n",
      "Error during translation to zh-CN: the JSON object must be str, bytes or bytearray, not NoneType. Retrying... (1/5)\n",
      "Error during translation to zh-CN: the JSON object must be str, bytes or bytearray, not NoneType. Retrying... (1/5)\n",
      "Error during translation to zh-CN: the JSON object must be str, bytes or bytearray, not NoneType. Retrying... (1/5)\n"
     ]
    }
   ],
   "source": [
    "twitter_data[\"zh_gs\"] = twitter_data.apply(lambda row: googletrans_tester(row[\"text\"], to='zh-CN'), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_data[\"zh_dp\"] = twitter_data.apply(lambda row: deep_tester(row[\"text\"], to='zh-CN'), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# twitter_data[\"zh_tr\"] = twitter_data.apply(lambda row: translate_tester(row[\"text\"], to='zh'), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76734     None\n",
       "105563    None\n",
       "46243     None\n",
       "147520    None\n",
       "79709     None\n",
       "          ... \n",
       "83397     None\n",
       "121606    None\n",
       "154144    None\n",
       "159522    None\n",
       "144468    None\n",
       "Length: 1000, dtype: object"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_data.apply(lambda row: calculation_helper(row[\"spacy_sentiment\"], row[\"zh_ts\"], zh_ts), axis=1)\n",
    "twitter_data.apply(lambda row: calculation_helper(row[\"spacy_sentiment\"], row[\"zh_gs\"], zh_gs), axis=1)\n",
    "twitter_data.apply(lambda row: calculation_helper(row[\"spacy_sentiment\"], row[\"zh_dp\"], zh_dp), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ts results\n",
      "rmse: 6.051968817849527, mae: 95.95956692084364\n",
      "positive accuracy: 0.8562, negative accuracy: 0.7959, neutral accuracy: 0.7968, total accuracy: 0.823\n",
      "\n",
      "gs results\n",
      "rmse: 7.431768125160275, mae: 137.77335536916792\n",
      "positive accuracy: 0.6899, negative accuracy: 0.6041, neutral accuracy: 0.7871, total accuracy: 0.699\n",
      "\n",
      "dp results\n",
      "rmse: 6.36531513004346, mae: 105.05997081699162\n",
      "positive accuracy: 0.8337, negative accuracy: 0.7837, neutral accuracy: 0.7968, total accuracy: 0.81\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nts results\")\n",
    "print_res(zh_ts)\n",
    "print(\"\\ngs results\")\n",
    "print_res(zh_gs)\n",
    "print(\"\\ndp results\")\n",
    "print_res(zh_dp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_data[\"ar_ts\"] = twitter_data.apply(lambda row: ts_tester(row[\"text\"], to='ar'), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during translation to ar: the JSON object must be str, bytes or bytearray, not NoneType. Retrying... (1/5)\n",
      "Error during translation to ar: the JSON object must be str, bytes or bytearray, not NoneType. Retrying... (2/5)\n",
      "Error during back translation to English: the JSON object must be str, bytes or bytearray, not NoneType. Retrying... (1/5)\n",
      "Error during translation to ar: the JSON object must be str, bytes or bytearray, not NoneType. Retrying... (1/5)\n",
      "Error during translation to ar: the JSON object must be str, bytes or bytearray, not NoneType. Retrying... (1/5)\n"
     ]
    }
   ],
   "source": [
    "twitter_data[\"ar_gs\"] = twitter_data.apply(lambda row: googletrans_tester(row[\"text\"], to='ar'), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_data[\"ar_dp\"] = twitter_data.apply(lambda row: deep_tester(row[\"text\"], to='ar'), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# twitter_data[\"ar_tr\"] = twitter_data.apply(lambda row: translate_tester(row[\"text\"], to='ar'), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76734     None\n",
       "105563    None\n",
       "46243     None\n",
       "147520    None\n",
       "79709     None\n",
       "          ... \n",
       "83397     None\n",
       "121606    None\n",
       "154144    None\n",
       "159522    None\n",
       "144468    None\n",
       "Length: 1000, dtype: object"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_data.apply(lambda row: calculation_helper(row[\"spacy_sentiment\"], row[\"ar_ts\"], ar_ts), axis=1)\n",
    "twitter_data.apply(lambda row: calculation_helper(row[\"spacy_sentiment\"], row[\"ar_gs\"], ar_gs), axis=1)\n",
    "twitter_data.apply(lambda row: calculation_helper(row[\"spacy_sentiment\"], row[\"ar_dp\"], ar_dp), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ts results\n",
      "rmse: 5.4324834591105935, mae: 84.35008922327677\n",
      "positive accuracy: 0.8607, negative accuracy: 0.8, neutral accuracy: 0.8065, total accuracy: 0.829\n",
      "\n",
      "gs results\n",
      "rmse: 6.426772199092459, mae: 113.1202286186036\n",
      "positive accuracy: 0.7573, negative accuracy: 0.6082, neutral accuracy: 0.8419, total accuracy: 0.747\n",
      "\n",
      "dp results\n",
      "rmse: 5.280968149721594, mae: 78.68333919321417\n",
      "positive accuracy: 0.8584, negative accuracy: 0.8245, neutral accuracy: 0.829, total accuracy: 0.841\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nts results\")\n",
    "print_res(ar_ts)\n",
    "print(\"\\ngs results\")\n",
    "print_res(ar_gs)\n",
    "print(\"\\ndp results\")\n",
    "print_res(ar_dp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
